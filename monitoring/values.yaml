# https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml
# https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md

# https://github.com/rancher/rancher/issues/29939#issuecomment-1193125841
defaultRules:
  disabled:
    # https://etcd.io/docs/v3.5/faq/#what-does-the-etcd-warning-apply-entries-took-too-long-mean
    # My disks are too slow. It should have 25ms, but I am putting on 50ms because there is too much noise
    # and it is not usefull. So let`s give a warning only when it is really high
    etcdHighCommitDurations: true
    # the results of this rule are not accurate: https://github.com/rancher/rancher/issues/29939
    etcdHighNumberOfFailedGRPCRequests: true
    Watchdog: true
  
additionalPrometheusRulesMap:
  additional-rules:
    groups:
      # fix etcdHighNumberOfFailedGRPCRequests alerting rules from above, adapted from: https://github.com/etcd-io/etcd/pull/13127
      - name: etcd-additional
        rules:
          - alert: etcdHighCommitDurationsWarning
            annotations:
              message: >-
                etcd cluster "{{ $labels.job }}": 99th percentile commit durations {{ $value }}s on etcd instance {{ $labels.instance }}.
            expr: >-
              histogram_quantile(0.99, rate(etcd_disk_backend_commit_duration_seconds_bucket{job=~".*etcd.*"}[5m])) > 0.50
            for: 10m
            labels:
              severity: warning
          - alert: etcdHighNumberOfFailedGRPCRequestsWarning
            annotations:
              message: >-
                etcd cluster "{{ $labels.job }}": {{ $value }}% of requests for {{
                $labels.grpc_method }} failed on etcd instance {{ $labels.instance
                }}.
            expr: >-
              100 * sum(rate(grpc_server_handled_total{job=~".*etcd.*",
                grpc_code=~"Unknown|FailedPrecondition|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded"}[5m])) 
              / 
              sum(rate(grpc_server_handled_total{job=~".*etcd.*"}[5m]))
              > 1
            for: 10m
            labels:
              severity: warning
          - alert: etcdHighNumberOfFailedGRPCRequestsCritical
            annotations:
              message: >-
                etcd cluster "{{ $labels.job }}": {{ $value }}% of requests for {{
                $labels.grpc_method }} failed on etcd instance {{ $labels.instance
                }}.
            expr: >-
              100 * sum(rate(grpc_server_handled_total{job=~".*etcd.*",
                grpc_code=~"Unknown|FailedPrecondition|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded"}[5m])) 
              / 
              sum(rate(grpc_server_handled_total{job=~".*etcd.*"}[5m]))
              > 5
            for: 5m
            labels:
              severity: critical

alertmanager:
  alertmanagerSpec:
    storage:
     volumeClaimTemplate:
       spec:
         storageClassName: replicated
         accessModes: ["ReadWriteOnce"]
         resources:
           requests:
             storage: 1Gi

# https://github.com/k3s-io/k3s/issues/3619
kubeControllerManager:
  enabled: true
  endpoints:
   - 192.168.179.103
   - 192.168.179.100
   - 192.168.179.120
  service:
    enabled: true
    port: 10257
    targetPort: 10257
  serviceMonitor:
    enabled: true
    https: true
    insecureSkipVerify: true

kubeScheduler:
  enabled: true
  endpoints:
   - 192.168.179.103
   - 192.168.179.100
   - 192.168.179.120
  service:
    enabled: true
    port: 10259
    targetPort: 10259
  serviceMonitor:
    enabled: true
    https: true
    insecureSkipVerify: true

kubeProxy:
  enabled: true
  endpoints:
   - 192.168.179.103
   - 192.168.179.100
   - 192.168.179.120
  service:
    enabled: true
    port: 10249
    targetPort: 10249

kubeEtcd:
  enabled: true
  endpoints:
   - 192.168.179.103
   - 192.168.179.100
   - 192.168.179.120
  service:
    enabled: true
    port: 2381
    targetPort: 2381


grafana:
  enabled: true

  extraSecretMounts:
    - name: auth-generic-oauth-secret-mount
      secretName: authentik-secret
      defaultMode: 0440
      mountPath: /etc/secrets/auth_generic_oauth
      readOnly: true

  plugins:
    # https://grafana.com/grafana/plugins/camptocamp-prometheus-alertmanager-datasource/
    - camptocamp-prometheus-alertmanager-datasource
    - grafana-piechart-panel

  grafana.ini:
    paths:
      data: /var/lib/grafana/data
      logs: /var/log/grafana
      plugins: /var/lib/grafana/plugins
      provisioning: /etc/grafana/provisioning
    analytics:
      check_for_updates: true
    log:
      mode: console
    grafana_net:
      url: https://grafana.net
    users:
      allow_sign_up: false
      auto_assign_org: true
      auto_assign_org_role: Editor
    server:
      root_url: "https://monitoring.anagno.dev"
    auth:
      oauth_auto_login: true
    auth.generic_oauth:
      name: auth.anagno.dev
      auto_sign_up: true
      enabled: true
      # https://github.com/helm/charts/issues/22473#issuecomment-662361020
      client_id: $__file{/etc/secrets/auth_generic_oauth/client_id}
      client_secret: $__file{/etc/secrets/auth_generic_oauth/client_secret}
      scopes: openid email profile
      auth_url: https://auth.anagno.dev/application/o/authorize/
      token_url: https://auth.anagno.dev/application/o/token/
      api_url: https://auth.anagno.dev/application/o/userinfo/
      role_attribute_path: contains(groups[*], 'caretakers') && 'Admin' || 'Viewer'

  sidecar:
    # For adding dashboards and datasources via ConfigMaps
    dashboards:
      enabled: true
      label: grafana_dashboard
      annotations: 
        monitoring-sidecar-dashboard-directory: "/tmp/dashboards/kubernetes"
    datasources:
      enabled: true
      defaultDatasourceEnabled: true
      createPrometheusReplicasDatasources: false
      label: grafana_datasource
      annotations: 
        monitoring-sidecar-datasource-directory: "/tmp/datasource/kubernetes"

  additionalDataSources:
    - name: Prometheus AlertManager
      orgId: 1
      type: camptocamp-prometheus-alertmanager-datasource
      url: http://{{ printf "%s-alertmanager" (include "kube-prometheus-stack.fullname" .)  }}:9093
      version: 1

prometheus:
  enabled: true
  service:
    clusterIP: ""
    port: 9090
    externalIPs: []
    type: ClusterIP

  prometheusSpec:
    resources:
      limits:
        memory: 6000Mi

    # https://github.com/rook/rook/issues/6680
    # This was necessary to be able to scrap the data for the Kubernetes/Compute Resources/* databoards
    # We need to be able to scrap the data from all the namespaces
    serviceMonitorSelectorNilUsesHelmValues: false
    serviceMonitorSelector: {}
    podMonitorSelectorNilUsesHelmValues: false
    podMonitorSelector: {}
    retention: 30d
    retentionSize: "25GiB"
    walCompression: true
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: replicated
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 30Gi

prometheusOperator:
  enabled: true
  prometheusConfigReloader:
    # resource config for prometheusConfigReloader
    # The default ones are causing some throttling
    # because the Raspberry pi is not powerfull enough
    resources: {}
  # Enable vertical pod autoscaler support for prometheus-operator
  verticalPodAutoscaler:
    enabled: yes

kube-state-metrics:
  verticalPodAutoscaler:
    enabled: true
  collectors:
    - certificatesigningrequests
    - configmaps
    - cronjobs
    - daemonsets
    - deployments
    - endpoints
    - horizontalpodautoscalers
    - ingresses
    - jobs
    - leases
    - limitranges
    - mutatingwebhookconfigurations
    - namespaces
    - networkpolicies
    - nodes
    - persistentvolumeclaims
    - persistentvolumes
    - poddisruptionbudgets
    - pods
    - replicasets
    - replicationcontrollers
    - resourcequotas
    - secrets
    - services
    - statefulsets
    - storageclasses
    - validatingwebhookconfigurations
    - volumeattachments
    - verticalpodautoscalers # not a default resource, see also: https://github.com/kubernetes/kube-state-metrics#enabling-verticalpodautoscalers

prometheus-node-exporter:
  verticalPodAutoscaler:
    enabled: true